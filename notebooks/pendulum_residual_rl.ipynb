{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkxk+nOPJ5YzbXFV8/IGHU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baronase/ml-residual-pendulum/blob/master/notebooks/pendulum_residual_rl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tngAnABMAq2w"
      },
      "outputs": [],
      "source": [
        "!pip -q install \"gymnasium[classic-control]\" stable-baselines3 torch numpy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- REPO SETUP --- Only run once\n",
        "!git clone https://github.com/baronase/ml-residual-pendulum.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3rNl61_WDDz",
        "outputId": "3c0001dc-16c7-4fe4-d046-db4479166797"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ml-residual-pendulum' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ml-residual-pendulum\n",
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0dBKsd4SRLt",
        "outputId": "9f47a608-090e-4118-f6cd-edb510d96011"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'ml-residual-pendulum'\n",
            "/content/ml-residual-pendulum\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 6 (delta 1), reused 6 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (6/6), 1.17 KiB | 1.17 MiB/s, done.\n",
            "From https://github.com/baronase/ml-residual-pendulum\n",
            "   3c881f9..2ba64cf  master     -> origin/master\n",
            "Updating 3c881f9..2ba64cf\n",
            "Fast-forward\n",
            " pyproject.toml                           |  3 \u001b[32m+++\u001b[m\n",
            " src/pendulum_residual_rl/residual_env.py | 42 \u001b[32m++++++++++++++++++++++++++++++++\u001b[m\n",
            " 2 files changed, 45 insertions(+)\n",
            " create mode 100644 src/pendulum_residual_rl/residual_env.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "PURE_SAC_MODEL_SAVE_PATH = \"/content/drive/MyDrive/pendulum_residual_rl/models/sac_pure_pendulum\"\n"
      ],
      "metadata": {
        "id": "QVB5Nxg0fVKd",
        "outputId": "5445c991-363d-4726-8f91-aa7259c8c0fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip uninstall -y pendulum_residual_rl\n",
        "!{sys.executable} -m pip install -e .\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkWJb3NEVcV_",
        "outputId": "b7ebe9f9-e41d-4cd6-bed1-dcb0850c1ed3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pendulum_residual_rl 0.1.0\n",
            "Uninstalling pendulum_residual_rl-0.1.0:\n",
            "  Successfully uninstalled pendulum_residual_rl-0.1.0\n",
            "Obtaining file:///content/ml-residual-pendulum\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gymnasium[classic-control] in /usr/local/lib/python3.12/dist-packages (from pendulum_residual_rl==0.1.0) (1.2.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[classic-control]->pendulum_residual_rl==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[classic-control]->pendulum_residual_rl==0.1.0) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[classic-control]->pendulum_residual_rl==0.1.0) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[classic-control]->pendulum_residual_rl==0.1.0) (0.0.4)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.12/dist-packages (from gymnasium[classic-control]->pendulum_residual_rl==0.1.0) (2.6.1)\n",
            "Building wheels for collected packages: pendulum_residual_rl\n",
            "  Building editable for pendulum_residual_rl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pendulum_residual_rl: filename=pendulum_residual_rl-0.1.0-0.editable-py3-none-any.whl size=1362 sha256=4ecc7faaf0efb1e1139387c1e6f42a95e50282740b47ebfb8fe8293270bb4ebd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lbniofhq/wheels/60/f4/4f/d02c1d5f55036909f72c6126ce700a1c121f66bb9d9c603732\n",
            "Successfully built pendulum_residual_rl\n",
            "Installing collected packages: pendulum_residual_rl\n",
            "Successfully installed pendulum_residual_rl-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#should restart the session here\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "3kuZbWAkfHdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verifying import\n",
        "import pendulum_residual_rl\n",
        "print(\"ok\", pendulum_residual_rl.__file__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJjQ5sobRFB5",
        "outputId": "9e3d62b1-02fe-4c53-b3fa-981c00e5c615"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ok /content/ml-residual-pendulum/src/pendulum_residual_rl/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "env = gym.make(\"Pendulum-v1\")\n",
        "obs, info = env.reset(seed=0)\n",
        "\n",
        "print(\"obs:\", obs)\n",
        "print(\"obs shape:\", obs.shape)\n",
        "print(\"action space:\", env.action_space)\n",
        "print(\"obs space:\", env.observation_space)\n",
        "\n",
        "# take a few random steps\n",
        "for i in range(5):\n",
        "    action = env.action_space.sample()\n",
        "    obs, reward, terminated, truncated, info = env.step(action)\n",
        "    print(i, \"action:\", action, \"reward:\", reward)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4Dc5AfUAv0g",
        "outputId": "ba61e2a0-4329-445e-ec44-65c89de937c1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "obs: [ 0.6520163   0.758205   -0.46042657]\n",
            "obs shape: (3,)\n",
            "action space: Box(-2.0, 2.0, (1,), float32)\n",
            "obs space: Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)\n",
            "0 action: [-1.1358683] reward: -0.763045506059638\n",
            "1 action: [-0.91034794] reward: -0.7364321191171552\n",
            "2 action: [0.97577316] reward: -0.7816729541931741\n",
            "3 action: [0.76915765] reward: -0.9852585065005565\n",
            "4 action: [1.6398454] reward: -1.3714675297078276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Debugging ;\n",
        "!pwd\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxmyY-X3Hgmt",
        "outputId": "ccb1629a-b8be-429f-cfe4-5e42e7af250c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "drive  ml-residual-pendulum  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code Files (additions to repo)"
      ],
      "metadata": {
        "id": "JUUY2vVHZWgi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No need to run this again, just for reference"
      ],
      "metadata": {
        "id": "BMkSXvU1ZwPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ml-residual-pendulum/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBo2Vv6DHl-n",
        "outputId": "5cef6c84-2e33-4060-e6d4-d41f5839d22f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ml-residual-pendulum\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/pendulum_residual_rl/controllers.py\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "import math\n",
        "import numpy as np\n",
        "#lalala\n",
        "\n",
        "def obs_to_theta_theta_dot(obs: np.ndarray) -> tuple[float, float]:\n",
        "    \"\"\"Pendulum-v1 obs = [cos(theta), sin(theta), theta_dot], with theta in [-pi, pi].\"\"\"\n",
        "    cos_t, sin_t, theta_dot = float(obs[0]), float(obs[1]), float(obs[2])\n",
        "    theta = math.atan2(sin_t, cos_t)\n",
        "    return theta, theta_dot\n",
        "\n",
        "\n",
        "def wrap_to_pi(angle: float) -> float:\n",
        "    \"\"\"Wrap angle to [-pi, pi].\"\"\"\n",
        "    return (angle + math.pi) % (2 * math.pi) - math.pi\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class EnergyPDController:\n",
        "    \"\"\"\n",
        "    Baseline controller: energy-shaping swing-up + PD stabilize near upright.\n",
        "\n",
        "    Conventions:\n",
        "      - Pendulum-v1 uses theta=0 as upright.\n",
        "      - We use a normalized energy:\n",
        "            E = 0.5 * theta_dot^2 + (1 + cos(theta))\n",
        "        so:\n",
        "            E* (upright, zero velocity) = 2.0\n",
        "            E (hanging down at pi, zero velocity) = 0.0\n",
        "\n",
        "    Action is torque u in [-max_torque, max_torque].\n",
        "    \"\"\"\n",
        "    # PD gains (used near upright)\n",
        "    kp: float\n",
        "    kd: float\n",
        "\n",
        "    # Energy shaping gain (used far from upright)\n",
        "    ke: float\n",
        "\n",
        "    # Switch/blend region (radians)\n",
        "    theta_switch: float # 0.5 ~ around ~28.6 degrees\n",
        "\n",
        "    # Residual scale not used here (for later); controller outputs full torque\n",
        "    max_torque: float\n",
        "\n",
        "    def __init__(self, kp_in: float = 10.0, kd_in: float = 1.0,\n",
        "                 ke_in: float = 2.0, theta_switch_in: float = 0.5,\n",
        "                 max_torque_in: float = 2.0, log_interval_in = 10) -> None:\n",
        "        self.kp = kp_in\n",
        "        self.kd = kd_in\n",
        "        self.ke = ke_in\n",
        "        self.theta_switch = theta_switch_in\n",
        "        self.max_torque = max_torque_in\n",
        "        # DEBUG\n",
        "        self.step_for_print = 0\n",
        "        self.log_interval = log_interval_in\n",
        "\n",
        "        # pendulum\n",
        "        self.pen_l = 1\n",
        "        self.pen_m = 1\n",
        "        self.pen_I = self.pen_m * (self.pen_l ** 2) / 3.0\n",
        "\n",
        "\n",
        "    def energy(self, theta: float, theta_dot: float) -> float:\n",
        "        # Ek = 0.5 * I * omega**2\n",
        "        Ek = 0.5 * self.pen_I * theta_dot**2\n",
        "        # Ep = m * g * l * (1.0 + math.cos(theta))   # Pendulum-v1 convention\n",
        "        Ep = 1 * 10 * self.pen_l / 2 * (1.0 + math.cos(theta))\n",
        "        return Ek + Ep\n",
        "\n",
        "    # def energy(self, theta: float, theta_dot: float) -> float:  # <--- ORIGINAL\n",
        "    #     return 0.5 * (theta_dot ** 2) + (1.0 + math.cos(theta))\n",
        "\n",
        "    def u_pd(self, theta: float, theta_dot: float) -> float:\n",
        "        # stabilize around theta=0\n",
        "        theta = wrap_to_pi(theta)\n",
        "        return -self.kp * theta - self.kd * theta_dot\n",
        "\n",
        "    def u_energy(self, theta: float, theta_dot: float) -> float:\n",
        "        # energy target: upright (theta=0, theta_dot=0) => E*=2\n",
        "        e = self.energy(theta, theta_dot) - 10.0  # positive => too much energy\n",
        "        # Pumping direction: \"push with the swing\" when energy is low, oppose when high\n",
        "        # direction = math.copysign(1.0, theta_dot * math.cos(theta) + 1e-6)  # <-- ORIGINAL\n",
        "        direction = math.copysign(1.0, theta_dot + 1e-6)\n",
        "        return -self.ke * e * direction\n",
        "\n",
        "\n",
        "    def blend_weight(self, theta: float) -> float:\n",
        "        \"\"\"\n",
        "        Weight for PD vs energy:\n",
        "          w=1 near upright, w=0 when |theta| >= theta_switch.\n",
        "        \"\"\"\n",
        "        a = abs(wrap_to_pi(theta))\n",
        "        if a >= self.theta_switch:\n",
        "            return 0.0\n",
        "        # smooth-ish ramp (quadratic)\n",
        "        x = 1.0 - (a / self.theta_switch)\n",
        "        return x * x\n",
        "\n",
        "    def __call__(self, obs: np.ndarray) -> np.ndarray:\n",
        "        # DEBUG\n",
        "        self.step_for_print += 1\n",
        "\n",
        "        theta, theta_dot = obs_to_theta_theta_dot(obs)\n",
        "        u_e = self.u_energy(theta, theta_dot)\n",
        "        u_p = self.u_pd(theta, theta_dot)\n",
        "\n",
        "        if self.step_for_print % self.log_interval == 0:\n",
        "          print(f\"step: {self.step_for_print} - x:{obs[0]:.2f}, y:{obs[1]:.2f} | theta:{theta:.2f} theta_dot:{theta_dot:.2f}\")\n",
        "\n",
        "\n",
        "        w = self.blend_weight(theta)\n",
        "        u = (1.0 - w) * u_e + w * u_p\n",
        "        if self.step_for_print % self.log_interval == 0:\n",
        "          print(f\"step: {self.step_for_print} - u_e:{u_e:.2f}, u_p:{u_p:.2f} | w:{w} u:{u:.2f}\")\n",
        "        # clip to env action bounds\n",
        "        u = float(np.clip(u, -self.max_torque, self.max_torque))\n",
        "        return np.array([u], dtype=np.float32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBSkypFBHOOd",
        "outputId": "2f6c4c84-7765-49dd-833a-9c9ebb8b1ef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/pendulum_residual_rl/controllers.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/pendulum_residual_rl/residual_env.py\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "class ResidualWrapper(gym.Wrapper):\n",
        "    \"\"\"\n",
        "    Wraps an env so that the agent outputs a residual action.\n",
        "    Env receives: u_total = clip(u_base + alpha * u_res, action_low, action_high)\n",
        "    \"\"\"\n",
        "    def __init__(self, env: gym.Env, baseline_fn, alpha: float = 0.3):\n",
        "        super().__init__(env)\n",
        "        self.baseline_fn = baseline_fn\n",
        "        self.alpha = float(alpha)\n",
        "\n",
        "        # Agent outputs residual in [-1, 1] (normalized)\n",
        "        self.action_space = gym.spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "\n",
        "        # original env bounds\n",
        "        self.low = float(env.action_space.low[0])\n",
        "        self.high = float(env.action_space.high[0])\n",
        "\n",
        "    def step(self, action):\n",
        "        obs = self.env.unwrapped.state if False else None  # (unused, just a hint)\n",
        "        # action is residual in [-1, 1]\n",
        "        u_res = float(np.clip(action[0], -1.0, 1.0))\n",
        "\n",
        "        # baseline action in env units\n",
        "        u_base = self.baseline_fn(self._last_obs)\n",
        "        u_base = float(u_base[0])\n",
        "\n",
        "        u_total = np.clip(u_base + self.alpha * u_res * (self.high - self.low) / 2.0, self.low, self.high)\n",
        "        self._last_obs, reward, term, trunc, info = self.env.step(np.array([u_total], dtype=np.float32))\n",
        "        info[\"u_base\"] = u_base\n",
        "        info[\"u_res\"] = u_res\n",
        "        info[\"u_total\"] = float(u_total)\n",
        "        return self._last_obs, reward, term, trunc, info\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        obs, info = self.env.reset(**kwargs)\n",
        "        self._last_obs = obs\n",
        "        return obs, info\n"
      ],
      "metadata": {
        "id": "XXbc1fvkZ3V_",
        "outputId": "be2e92c3-0a93-4b01-d5de-d02b62da7365",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/pendulum_residual_rl/residual_env.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "Hwsy3B7VZihw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_plots(thetas, dots, us, rewards):\n",
        "  plt.figure(figsize=(2, 2))\n",
        "  plt.plot(thetas)\n",
        "  plt.title(\"theta(t)\")\n",
        "  plt.xlabel(\"t\")\n",
        "  plt.ylabel(\"theta (rad)\")\n",
        "  # plt.figsize(2,2)\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure(figsize=(2, 2))\n",
        "  plt.plot(dots)\n",
        "  plt.title(\"dot(t)\")\n",
        "  plt.xlabel(\"t\")\n",
        "  plt.ylabel(\"angular velocity\")\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  plt.figure(figsize=(2, 2))\n",
        "  plt.plot(us)\n",
        "  plt.title(\"u(t)\")\n",
        "  plt.xlabel(\"t\")\n",
        "  plt.ylabel(\"torque\")\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure(figsize=(2, 2))\n",
        "  plt.plot(rewards)\n",
        "  plt.title(\"reward(t)\")\n",
        "  plt.xlabel(\"t\")\n",
        "  plt.ylabel(\"reward\")\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "0EVwGRsHNV6m"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Debugging ;\n",
        "def obs_to_theta_theta_dot(obs: np.ndarray) -> tuple[float, float]:\n",
        "    \"\"\"Pendulum-v1 obs = [cos(theta), sin(theta), theta_dot], with theta in [-pi, pi].\"\"\"\n",
        "    cos_t, sin_t, theta_dot = float(obs[0]), float(obs[1]), float(obs[2])\n",
        "    theta = math.atan2(sin_t, cos_t)\n",
        "    return theta, theta_dot\n",
        "\n",
        "class TestCtrl:\n",
        "  # tests\n",
        "  def __init__(self):\n",
        "    self.hit_bot = False\n",
        "    self.step_for_print = 0\n",
        "    self.log_interval = 10\n",
        "  def __call__(self, obs: np.ndarray):\n",
        "    theta, theta_dot = obs_to_theta_theta_dot(obs)\n",
        "\n",
        "    self.step_for_print += 1\n",
        "    if self.step_for_print % self.log_interval == 0:\n",
        "      print(f\"step: {self.step_for_print} - x:{obs[0]}, y:{obs[1]} | theta:{theta} theta_dot:{theta_dot}\")\n",
        "\n",
        "    self.log_interval\n",
        "\n",
        "    if (3.13 < theta or theta < -3.13) and -0.01 < theta_dot < 0.01:\n",
        "      print(f\"HIT BOT NOW: step:{self.step_for_print}\")\n",
        "      self.hit_bot = True\n",
        "\n",
        "    if self.hit_bot:\n",
        "      return np.array([2], dtype=np.float32)\n",
        "    else:\n",
        "      u = -np.sign(theta_dot) * 0.2\n",
        "      return np.array([u], dtype=np.float32)"
      ],
      "metadata": {
        "id": "qt607vFpN_Yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Debugging ;\n",
        "env = gym.make(\"Pendulum-v1\")\n",
        "p = env.unwrapped   # unwrap TimeLimit / other wrappers\n",
        "\n",
        "print(\"m =\", p.m)\n",
        "print(\"l =\", p.l)\n",
        "print(\"g =\", p.g)\n",
        "print(\"dt =\", p.dt)\n",
        "print(\"max_torque =\", p.max_torque)"
      ],
      "metadata": {
        "id": "XFW-k7fdQ-n6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pendulum_residual_rl.controllers import EnergyPDController, obs_to_theta_theta_dot\n",
        "\n",
        "env = gym.make(\"Pendulum-v1\")\n",
        "\n",
        "if True:\n",
        "  print(\"using baseline control !!\")\n",
        "  ctrl = EnergyPDController(log_interval_in=100000)\n",
        "  print(f\"kp:{ctrl.kp}, kd:{ctrl.kd}, ke:{ctrl.ke}, theta_switch:{ctrl.theta_switch}\")\n",
        "else:\n",
        "  print(\"using test control !!\")\n",
        "  ctrl = TestCtrl()\n",
        "\n",
        "def rollout(seed=0, steps=200):\n",
        "    obs, _ = env.reset(seed=seed)\n",
        "    thetas, dots, us, rewards = [], [], [], []\n",
        "    for _ in range(steps):\n",
        "        u = ctrl(obs)\n",
        "        obs, r, term, trunc, _ = env.step(u)\n",
        "        theta, theta_dot = obs_to_theta_theta_dot(obs)\n",
        "        thetas.append(theta)\n",
        "        dots.append(theta_dot)\n",
        "        us.append(float(u[0]))\n",
        "        rewards.append(r)\n",
        "        if term or trunc:\n",
        "            break\n",
        "    return np.array(thetas), np.array(dots), np.array(us), np.array(rewards)\n",
        "\n",
        "if True:\n",
        "  print(f\"running a few seeds\")\n",
        "  for i in (0,1,2,3,4,5):\n",
        "    thetas, dots, us, rewards = rollout(seed=i, steps=200)\n",
        "    print(f\"episode {i} return:\", rewards.sum())\n",
        "else:\n",
        "  _seed = 3\n",
        "  print(f\"doing a single test run, seed={_seed}\")\n",
        "  thetas, dots, us, rewards = rollout(seed=_seed, steps=200)\n",
        "  print_plots(thetas, dots, us, rewards)\n",
        "  print(\"episode return:\", rewards.sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arhUWCb0HTsV",
        "outputId": "a8fa941b-ddcf-4125-d4d1-1bef60a87b0d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using baseline control !!\n",
            "kp:10.0, kd:1.0, ke:5.0, theta_switch:0.3\n",
            "running a few seeds\n",
            "episode 0 return: -123.07517840332312\n",
            "episode 1 return: -125.99658863321612\n",
            "episode 2 return: -115.93665980187\n",
            "episode 3 return: -233.36031988440666\n",
            "episode 4 return: -240.00514565727724\n",
            "episode 5 return: -113.97715523907242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# measure - eval over many episodes\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "from pendulum_residual_rl.controllers import EnergyPDController\n",
        "\n",
        "env = gym.make(\"Pendulum-v1\")\n",
        "ctrl = EnergyPDController(log_interval_in=1000000)\n",
        "\n",
        "def eval_controller(n_episodes=50, seed=0, steps=200):\n",
        "    returns = []\n",
        "    for i in range(n_episodes):\n",
        "        obs, _ = env.reset(seed=seed + i)\n",
        "        total = 0.0\n",
        "        for _ in range(steps):\n",
        "            action = ctrl(obs)\n",
        "            obs, r, term, trunc, _ = env.step(action)\n",
        "            total += r\n",
        "            if term or trunc:\n",
        "                break\n",
        "        returns.append(total)\n",
        "    return float(np.mean(returns)), float(np.std(returns))\n",
        "\n",
        "mean_r, std_r = eval_controller(n_episodes=50, seed=0)\n",
        "print(\"Baseline mean return:\", mean_r)\n",
        "print(\"Baseline std:\", std_r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5_eSuBb93q5",
        "outputId": "dd57ae2d-0320-4db7-fc05-949ed2e63e57"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline mean return: -162.2092957654325\n",
            "Baseline std: 74.28399628048706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Debugging ;\n",
        "for i, th in enumerate(thetas[:40]):\n",
        "  print(f\"{i}:{th}\")"
      ],
      "metadata": {
        "id": "TeC_gLViTG6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Debugging ;\n",
        "for i, rw in enumerate(rewards[:70]):\n",
        "  print(f\"{i}:{rw}\")"
      ],
      "metadata": {
        "id": "n4GGCrpiAvRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Pure RL SAC Benchmark"
      ],
      "metadata": {
        "id": "W1kxw8sfNj9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eval function\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "def eval_policy(env_id, policy_fn, n_episodes=50, seed=0, steps=200):\n",
        "    env = gym.make(env_id)\n",
        "    returns = []\n",
        "    for i in range(n_episodes):\n",
        "        obs, _ = env.reset(seed=seed + i)\n",
        "        total = 0.0\n",
        "        for _ in range(steps):\n",
        "            action = policy_fn(obs)\n",
        "            obs, r, term, trunc, _ = env.step(action)\n",
        "            total += r\n",
        "            if term or trunc:\n",
        "                break\n",
        "        returns.append(total)\n",
        "    env.close()\n",
        "    return float(np.mean(returns)), float(np.std(returns))\n"
      ],
      "metadata": {
        "id": "LWlqTaPXNhLV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install stable-baselines3"
      ],
      "metadata": {
        "id": "TeNYzELKN7Uh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Pure SAC\n",
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "\n",
        "ENV_ID = \"Pendulum-v1\"\n",
        "\n",
        "# vectorized env is best practice for SB3\n",
        "train_env = make_vec_env(ENV_ID, n_envs=8, seed=0)\n",
        "\n",
        "# a pretty standard SAC config\n",
        "model_sac = SAC(\n",
        "    policy=\"MlpPolicy\",\n",
        "    env=train_env,\n",
        "    verbose=1,\n",
        "    seed=0,\n",
        ")\n",
        "\n",
        "model_sac.learn(total_timesteps=200_000)\n",
        "model_sac.save(\"sac_pure_pendulum\")\n"
      ],
      "metadata": {
        "id": "7ZxhZZBGN85C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Trained model\n",
        "model_sac.save(PURE_SAC_MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "g4CA3ax1g4QD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PURE_SAC_MODEL_SAVE_PATH = \"/content/drive/MyDrive/pendulum_residual_rl/models/sac_pure_pendulum\"\n",
        "ENV_ID = \"Pendulum-v1\""
      ],
      "metadata": {
        "id": "eefYSiUBk0eW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Trained model\n",
        "from stable_baselines3 import SAC\n",
        "\n",
        "model_sac_load = SAC.load(PURE_SAC_MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "AYSpfEiDhtPT",
        "outputId": "0dc8316a-4fe0-4998-8683-399df361ef87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sac_policy(obs):\n",
        "    action, _ = model_sac_load.predict(obs, deterministic=True)\n",
        "    return action\n",
        "\n",
        "mean_sac, std_sac = eval_policy(ENV_ID, sac_policy, n_episodes=50, seed=0)\n",
        "print(f\"Pure SAC mean return:{mean_sac:.5}\")\n",
        "print(f\"Pure SAC std:{std_sac:.5}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8XOilSgOa4r",
        "outputId": "3c2c02b9-4586-4a2e-9fb2-a887f8603221"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pure SAC mean return:-134.26\n",
            "Pure SAC std:79.293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pendulum_residual_rl.controllers import EnergyPDController\n",
        "\n",
        "ctrl = EnergyPDController(log_interval_in=100000)\n",
        "ctrl_mean, ctrl_std = eval_policy(ENV_ID, ctrl, n_episodes=50, seed=0)\n",
        "print(f\"CTRL mean return:{ctrl_mean:.5}\")\n",
        "print(f\"CTRL std: {ctrl_std:.5}\")"
      ],
      "metadata": {
        "outputId": "91f065d7-0208-421c-bb10-8b2e88d46637",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maJn3yaYSn2E"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CTRL mean return:-162.21\n",
            "CTRL std: 74.284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "\n",
        "from pendulum_residual_rl.residual_env import ResidualWrapper\n",
        "from pendulum_residual_rl.controllers import EnergyPDController\n",
        "\n",
        "baseline_ctrl = EnergyPDController(log_interval_in=100000)\n",
        "\n",
        "def make_residual_env():\n",
        "    env = gym.make(\"Pendulum-v1\")\n",
        "    return ResidualWrapper(env, baseline_fn=baseline_ctrl, alpha=0.3)\n",
        "\n",
        "train_env_res = make_vec_env(make_residual_env, n_envs=8, seed=0)\n",
        "\n",
        "policy_kwargs = dict(net_arch=[64, 64])  # smaller than SB3 default\n",
        "\n",
        "model_res = SAC(\n",
        "    \"MlpPolicy\",\n",
        "    train_env_res,\n",
        "    verbose=1,\n",
        "    seed=0,\n",
        "    policy_kwargs=policy_kwargs,\n",
        ")\n",
        "\n",
        "model_res.learn(total_timesteps=100_000)\n",
        "model_res.save(\"sac_residual_pendulum\")\n"
      ],
      "metadata": {
        "id": "03CynXG23pX5",
        "outputId": "c396ec11-df6c-46f0-f985-1c8469682cbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -398     |\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 798      |\n",
            "|    time_elapsed    | 2        |\n",
            "|    total_timesteps | 1600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.59     |\n",
            "|    critic_loss     | 2.59     |\n",
            "|    ent_coef        | 0.945    |\n",
            "|    ent_coef_loss   | -0.0938  |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 187      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -398     |\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 797      |\n",
            "|    time_elapsed    | 2        |\n",
            "|    total_timesteps | 1600     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -360     |\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 829      |\n",
            "|    time_elapsed    | 3        |\n",
            "|    total_timesteps | 3200     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.54     |\n",
            "|    critic_loss     | 1.18     |\n",
            "|    ent_coef        | 0.89     |\n",
            "|    ent_coef_loss   | -0.196   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 387      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -360     |\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 829      |\n",
            "|    time_elapsed    | 3        |\n",
            "|    total_timesteps | 3200     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -330     |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 824      |\n",
            "|    time_elapsed    | 5        |\n",
            "|    total_timesteps | 4800     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.83     |\n",
            "|    critic_loss     | 0.617    |\n",
            "|    ent_coef        | 0.838    |\n",
            "|    ent_coef_loss   | -0.298   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 587      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -330     |\n",
            "| time/              |          |\n",
            "|    episodes        | 24       |\n",
            "|    fps             | 824      |\n",
            "|    time_elapsed    | 5        |\n",
            "|    total_timesteps | 4800     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -324     |\n",
            "| time/              |          |\n",
            "|    episodes        | 28       |\n",
            "|    fps             | 776      |\n",
            "|    time_elapsed    | 8        |\n",
            "|    total_timesteps | 6400     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.87     |\n",
            "|    critic_loss     | 0.278    |\n",
            "|    ent_coef        | 0.789    |\n",
            "|    ent_coef_loss   | -0.399   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 787      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -324     |\n",
            "| time/              |          |\n",
            "|    episodes        | 32       |\n",
            "|    fps             | 776      |\n",
            "|    time_elapsed    | 8        |\n",
            "|    total_timesteps | 6400     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -336     |\n",
            "| time/              |          |\n",
            "|    episodes        | 36       |\n",
            "|    fps             | 774      |\n",
            "|    time_elapsed    | 10       |\n",
            "|    total_timesteps | 8000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.91     |\n",
            "|    critic_loss     | 0.21     |\n",
            "|    ent_coef        | 0.743    |\n",
            "|    ent_coef_loss   | -0.493   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 987      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -336     |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 774      |\n",
            "|    time_elapsed    | 10       |\n",
            "|    total_timesteps | 8000     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -349     |\n",
            "| time/              |          |\n",
            "|    episodes        | 44       |\n",
            "|    fps             | 792      |\n",
            "|    time_elapsed    | 12       |\n",
            "|    total_timesteps | 9600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 7.13     |\n",
            "|    critic_loss     | 0.197    |\n",
            "|    ent_coef        | 0.7      |\n",
            "|    ent_coef_loss   | -0.586   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 1187     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -349     |\n",
            "| time/              |          |\n",
            "|    episodes        | 48       |\n",
            "|    fps             | 792      |\n",
            "|    time_elapsed    | 12       |\n",
            "|    total_timesteps | 9600     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -345     |\n",
            "| time/              |          |\n",
            "|    episodes        | 52       |\n",
            "|    fps             | 801      |\n",
            "|    time_elapsed    | 13       |\n",
            "|    total_timesteps | 11200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 9.73     |\n",
            "|    critic_loss     | 0.332    |\n",
            "|    ent_coef        | 0.66     |\n",
            "|    ent_coef_loss   | -0.694   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 1387     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -345     |\n",
            "| time/              |          |\n",
            "|    episodes        | 56       |\n",
            "|    fps             | 801      |\n",
            "|    time_elapsed    | 13       |\n",
            "|    total_timesteps | 11200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -340     |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 809      |\n",
            "|    time_elapsed    | 15       |\n",
            "|    total_timesteps | 12800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 8.84     |\n",
            "|    critic_loss     | 0.328    |\n",
            "|    ent_coef        | 0.622    |\n",
            "|    ent_coef_loss   | -0.784   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 1587     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -340     |\n",
            "| time/              |          |\n",
            "|    episodes        | 64       |\n",
            "|    fps             | 809      |\n",
            "|    time_elapsed    | 15       |\n",
            "|    total_timesteps | 12800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -353     |\n",
            "| time/              |          |\n",
            "|    episodes        | 68       |\n",
            "|    fps             | 814      |\n",
            "|    time_elapsed    | 17       |\n",
            "|    total_timesteps | 14400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 8.89     |\n",
            "|    critic_loss     | 0.506    |\n",
            "|    ent_coef        | 0.586    |\n",
            "|    ent_coef_loss   | -0.884   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 1787     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -353     |\n",
            "| time/              |          |\n",
            "|    episodes        | 72       |\n",
            "|    fps             | 814      |\n",
            "|    time_elapsed    | 17       |\n",
            "|    total_timesteps | 14400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -349     |\n",
            "| time/              |          |\n",
            "|    episodes        | 76       |\n",
            "|    fps             | 809      |\n",
            "|    time_elapsed    | 19       |\n",
            "|    total_timesteps | 16000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 6.65     |\n",
            "|    critic_loss     | 0.882    |\n",
            "|    ent_coef        | 0.552    |\n",
            "|    ent_coef_loss   | -0.971   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 1987     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -349     |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 809      |\n",
            "|    time_elapsed    | 19       |\n",
            "|    total_timesteps | 16000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -346     |\n",
            "| time/              |          |\n",
            "|    episodes        | 84       |\n",
            "|    fps             | 804      |\n",
            "|    time_elapsed    | 21       |\n",
            "|    total_timesteps | 17600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.9     |\n",
            "|    critic_loss     | 1.15     |\n",
            "|    ent_coef        | 0.52     |\n",
            "|    ent_coef_loss   | -1.08    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 2187     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -346     |\n",
            "| time/              |          |\n",
            "|    episodes        | 88       |\n",
            "|    fps             | 804      |\n",
            "|    time_elapsed    | 21       |\n",
            "|    total_timesteps | 17600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -334     |\n",
            "| time/              |          |\n",
            "|    episodes        | 92       |\n",
            "|    fps             | 808      |\n",
            "|    time_elapsed    | 23       |\n",
            "|    total_timesteps | 19200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.7     |\n",
            "|    critic_loss     | 1.37     |\n",
            "|    ent_coef        | 0.49     |\n",
            "|    ent_coef_loss   | -1.13    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 2387     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -334     |\n",
            "| time/              |          |\n",
            "|    episodes        | 96       |\n",
            "|    fps             | 808      |\n",
            "|    time_elapsed    | 23       |\n",
            "|    total_timesteps | 19200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -323     |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 811      |\n",
            "|    time_elapsed    | 25       |\n",
            "|    total_timesteps | 20800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.3     |\n",
            "|    critic_loss     | 2.29     |\n",
            "|    ent_coef        | 0.462    |\n",
            "|    ent_coef_loss   | -1.29    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 2587     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -323     |\n",
            "| time/              |          |\n",
            "|    episodes        | 104      |\n",
            "|    fps             | 810      |\n",
            "|    time_elapsed    | 25       |\n",
            "|    total_timesteps | 20800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -304     |\n",
            "| time/              |          |\n",
            "|    episodes        | 108      |\n",
            "|    fps             | 813      |\n",
            "|    time_elapsed    | 27       |\n",
            "|    total_timesteps | 22400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.4     |\n",
            "|    critic_loss     | 2.75     |\n",
            "|    ent_coef        | 0.437    |\n",
            "|    ent_coef_loss   | -1.32    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 2787     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -304     |\n",
            "| time/              |          |\n",
            "|    episodes        | 112      |\n",
            "|    fps             | 813      |\n",
            "|    time_elapsed    | 27       |\n",
            "|    total_timesteps | 22400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -300     |\n",
            "| time/              |          |\n",
            "|    episodes        | 116      |\n",
            "|    fps             | 817      |\n",
            "|    time_elapsed    | 29       |\n",
            "|    total_timesteps | 24000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 14.9     |\n",
            "|    critic_loss     | 4.77     |\n",
            "|    ent_coef        | 0.413    |\n",
            "|    ent_coef_loss   | -1.33    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 2987     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -300     |\n",
            "| time/              |          |\n",
            "|    episodes        | 120      |\n",
            "|    fps             | 817      |\n",
            "|    time_elapsed    | 29       |\n",
            "|    total_timesteps | 24000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -283     |\n",
            "| time/              |          |\n",
            "|    episodes        | 124      |\n",
            "|    fps             | 812      |\n",
            "|    time_elapsed    | 31       |\n",
            "|    total_timesteps | 25600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 18.3     |\n",
            "|    critic_loss     | 5        |\n",
            "|    ent_coef        | 0.391    |\n",
            "|    ent_coef_loss   | -1.39    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 3187     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -283     |\n",
            "| time/              |          |\n",
            "|    episodes        | 128      |\n",
            "|    fps             | 811      |\n",
            "|    time_elapsed    | 31       |\n",
            "|    total_timesteps | 25600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -266     |\n",
            "| time/              |          |\n",
            "|    episodes        | 132      |\n",
            "|    fps             | 805      |\n",
            "|    time_elapsed    | 33       |\n",
            "|    total_timesteps | 27200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 10.5     |\n",
            "|    critic_loss     | 3.42     |\n",
            "|    ent_coef        | 0.371    |\n",
            "|    ent_coef_loss   | -1.41    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 3387     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -266     |\n",
            "| time/              |          |\n",
            "|    episodes        | 136      |\n",
            "|    fps             | 805      |\n",
            "|    time_elapsed    | 33       |\n",
            "|    total_timesteps | 27200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -242     |\n",
            "| time/              |          |\n",
            "|    episodes        | 140      |\n",
            "|    fps             | 809      |\n",
            "|    time_elapsed    | 35       |\n",
            "|    total_timesteps | 28800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.7     |\n",
            "|    critic_loss     | 4.87     |\n",
            "|    ent_coef        | 0.352    |\n",
            "|    ent_coef_loss   | -1.3     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 3587     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -242     |\n",
            "| time/              |          |\n",
            "|    episodes        | 144      |\n",
            "|    fps             | 809      |\n",
            "|    time_elapsed    | 35       |\n",
            "|    total_timesteps | 28800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -219     |\n",
            "| time/              |          |\n",
            "|    episodes        | 148      |\n",
            "|    fps             | 813      |\n",
            "|    time_elapsed    | 37       |\n",
            "|    total_timesteps | 30400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 15.5     |\n",
            "|    critic_loss     | 6.12     |\n",
            "|    ent_coef        | 0.334    |\n",
            "|    ent_coef_loss   | -1.41    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 3787     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -219     |\n",
            "| time/              |          |\n",
            "|    episodes        | 152      |\n",
            "|    fps             | 813      |\n",
            "|    time_elapsed    | 37       |\n",
            "|    total_timesteps | 30400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -214     |\n",
            "| time/              |          |\n",
            "|    episodes        | 156      |\n",
            "|    fps             | 816      |\n",
            "|    time_elapsed    | 39       |\n",
            "|    total_timesteps | 32000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.8     |\n",
            "|    critic_loss     | 7.01     |\n",
            "|    ent_coef        | 0.318    |\n",
            "|    ent_coef_loss   | -1.32    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 3987     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -214     |\n",
            "| time/              |          |\n",
            "|    episodes        | 160      |\n",
            "|    fps             | 816      |\n",
            "|    time_elapsed    | 39       |\n",
            "|    total_timesteps | 32000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -190     |\n",
            "| time/              |          |\n",
            "|    episodes        | 164      |\n",
            "|    fps             | 819      |\n",
            "|    time_elapsed    | 41       |\n",
            "|    total_timesteps | 33600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.4     |\n",
            "|    critic_loss     | 4.89     |\n",
            "|    ent_coef        | 0.303    |\n",
            "|    ent_coef_loss   | -1.28    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 4187     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -190     |\n",
            "| time/              |          |\n",
            "|    episodes        | 168      |\n",
            "|    fps             | 819      |\n",
            "|    time_elapsed    | 41       |\n",
            "|    total_timesteps | 33600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -172     |\n",
            "| time/              |          |\n",
            "|    episodes        | 172      |\n",
            "|    fps             | 822      |\n",
            "|    time_elapsed    | 42       |\n",
            "|    total_timesteps | 35200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.1     |\n",
            "|    critic_loss     | 4.79     |\n",
            "|    ent_coef        | 0.288    |\n",
            "|    ent_coef_loss   | -1.49    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 4387     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -172     |\n",
            "| time/              |          |\n",
            "|    episodes        | 176      |\n",
            "|    fps             | 822      |\n",
            "|    time_elapsed    | 42       |\n",
            "|    total_timesteps | 35200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -151     |\n",
            "| time/              |          |\n",
            "|    episodes        | 180      |\n",
            "|    fps             | 814      |\n",
            "|    time_elapsed    | 45       |\n",
            "|    total_timesteps | 36800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.2     |\n",
            "|    critic_loss     | 6.25     |\n",
            "|    ent_coef        | 0.274    |\n",
            "|    ent_coef_loss   | -1.38    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 4587     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -151     |\n",
            "| time/              |          |\n",
            "|    episodes        | 184      |\n",
            "|    fps             | 814      |\n",
            "|    time_elapsed    | 45       |\n",
            "|    total_timesteps | 36800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -143     |\n",
            "| time/              |          |\n",
            "|    episodes        | 188      |\n",
            "|    fps             | 817      |\n",
            "|    time_elapsed    | 46       |\n",
            "|    total_timesteps | 38400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.5     |\n",
            "|    critic_loss     | 5.28     |\n",
            "|    ent_coef        | 0.26     |\n",
            "|    ent_coef_loss   | -1.52    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 4787     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -143     |\n",
            "| time/              |          |\n",
            "|    episodes        | 192      |\n",
            "|    fps             | 817      |\n",
            "|    time_elapsed    | 46       |\n",
            "|    total_timesteps | 38400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -143     |\n",
            "| time/              |          |\n",
            "|    episodes        | 196      |\n",
            "|    fps             | 820      |\n",
            "|    time_elapsed    | 48       |\n",
            "|    total_timesteps | 40000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.2     |\n",
            "|    critic_loss     | 5.05     |\n",
            "|    ent_coef        | 0.247    |\n",
            "|    ent_coef_loss   | -1.49    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 4987     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -143     |\n",
            "| time/              |          |\n",
            "|    episodes        | 200      |\n",
            "|    fps             | 820      |\n",
            "|    time_elapsed    | 48       |\n",
            "|    total_timesteps | 40000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -144     |\n",
            "| time/              |          |\n",
            "|    episodes        | 204      |\n",
            "|    fps             | 822      |\n",
            "|    time_elapsed    | 50       |\n",
            "|    total_timesteps | 41600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 8.87     |\n",
            "|    critic_loss     | 4.69     |\n",
            "|    ent_coef        | 0.234    |\n",
            "|    ent_coef_loss   | -1.79    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 5187     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -144     |\n",
            "| time/              |          |\n",
            "|    episodes        | 208      |\n",
            "|    fps             | 822      |\n",
            "|    time_elapsed    | 50       |\n",
            "|    total_timesteps | 41600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -145     |\n",
            "| time/              |          |\n",
            "|    episodes        | 212      |\n",
            "|    fps             | 825      |\n",
            "|    time_elapsed    | 52       |\n",
            "|    total_timesteps | 43200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 10.9     |\n",
            "|    critic_loss     | 4.46     |\n",
            "|    ent_coef        | 0.221    |\n",
            "|    ent_coef_loss   | -1.75    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 5387     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -145     |\n",
            "| time/              |          |\n",
            "|    episodes        | 216      |\n",
            "|    fps             | 825      |\n",
            "|    time_elapsed    | 52       |\n",
            "|    total_timesteps | 43200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -146     |\n",
            "| time/              |          |\n",
            "|    episodes        | 220      |\n",
            "|    fps             | 827      |\n",
            "|    time_elapsed    | 54       |\n",
            "|    total_timesteps | 44800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 15.7     |\n",
            "|    critic_loss     | 7.51     |\n",
            "|    ent_coef        | 0.209    |\n",
            "|    ent_coef_loss   | -1.47    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 5587     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -146     |\n",
            "| time/              |          |\n",
            "|    episodes        | 224      |\n",
            "|    fps             | 827      |\n",
            "|    time_elapsed    | 54       |\n",
            "|    total_timesteps | 44800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -143     |\n",
            "| time/              |          |\n",
            "|    episodes        | 228      |\n",
            "|    fps             | 817      |\n",
            "|    time_elapsed    | 56       |\n",
            "|    total_timesteps | 46400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 10.4     |\n",
            "|    critic_loss     | 3.72     |\n",
            "|    ent_coef        | 0.198    |\n",
            "|    ent_coef_loss   | -1.73    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 5787     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -143     |\n",
            "| time/              |          |\n",
            "|    episodes        | 232      |\n",
            "|    fps             | 816      |\n",
            "|    time_elapsed    | 56       |\n",
            "|    total_timesteps | 46400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -149     |\n",
            "| time/              |          |\n",
            "|    episodes        | 236      |\n",
            "|    fps             | 817      |\n",
            "|    time_elapsed    | 58       |\n",
            "|    total_timesteps | 48000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.4     |\n",
            "|    critic_loss     | 4.19     |\n",
            "|    ent_coef        | 0.188    |\n",
            "|    ent_coef_loss   | -1.63    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 5987     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -149     |\n",
            "| time/              |          |\n",
            "|    episodes        | 240      |\n",
            "|    fps             | 817      |\n",
            "|    time_elapsed    | 58       |\n",
            "|    total_timesteps | 48000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -149     |\n",
            "| time/              |          |\n",
            "|    episodes        | 244      |\n",
            "|    fps             | 818      |\n",
            "|    time_elapsed    | 60       |\n",
            "|    total_timesteps | 49600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.8     |\n",
            "|    critic_loss     | 4.37     |\n",
            "|    ent_coef        | 0.178    |\n",
            "|    ent_coef_loss   | -1.74    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 6187     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -149     |\n",
            "| time/              |          |\n",
            "|    episodes        | 248      |\n",
            "|    fps             | 818      |\n",
            "|    time_elapsed    | 60       |\n",
            "|    total_timesteps | 49600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -149     |\n",
            "| time/              |          |\n",
            "|    episodes        | 252      |\n",
            "|    fps             | 817      |\n",
            "|    time_elapsed    | 62       |\n",
            "|    total_timesteps | 51200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.3     |\n",
            "|    critic_loss     | 5.52     |\n",
            "|    ent_coef        | 0.169    |\n",
            "|    ent_coef_loss   | -1.65    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 6387     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -149     |\n",
            "| time/              |          |\n",
            "|    episodes        | 256      |\n",
            "|    fps             | 817      |\n",
            "|    time_elapsed    | 62       |\n",
            "|    total_timesteps | 51200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -151     |\n",
            "| time/              |          |\n",
            "|    episodes        | 260      |\n",
            "|    fps             | 816      |\n",
            "|    time_elapsed    | 64       |\n",
            "|    total_timesteps | 52800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12       |\n",
            "|    critic_loss     | 2.97     |\n",
            "|    ent_coef        | 0.16     |\n",
            "|    ent_coef_loss   | -1.82    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 6587     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -151     |\n",
            "| time/              |          |\n",
            "|    episodes        | 264      |\n",
            "|    fps             | 816      |\n",
            "|    time_elapsed    | 64       |\n",
            "|    total_timesteps | 52800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -156     |\n",
            "| time/              |          |\n",
            "|    episodes        | 268      |\n",
            "|    fps             | 816      |\n",
            "|    time_elapsed    | 66       |\n",
            "|    total_timesteps | 54400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 17.8     |\n",
            "|    critic_loss     | 5.57     |\n",
            "|    ent_coef        | 0.152    |\n",
            "|    ent_coef_loss   | -1.76    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 6787     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -156     |\n",
            "| time/              |          |\n",
            "|    episodes        | 272      |\n",
            "|    fps             | 816      |\n",
            "|    time_elapsed    | 66       |\n",
            "|    total_timesteps | 54400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -161     |\n",
            "| time/              |          |\n",
            "|    episodes        | 276      |\n",
            "|    fps             | 809      |\n",
            "|    time_elapsed    | 69       |\n",
            "|    total_timesteps | 56000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 14.2     |\n",
            "|    critic_loss     | 7.69     |\n",
            "|    ent_coef        | 0.145    |\n",
            "|    ent_coef_loss   | -1.39    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 6987     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -161     |\n",
            "| time/              |          |\n",
            "|    episodes        | 280      |\n",
            "|    fps             | 809      |\n",
            "|    time_elapsed    | 69       |\n",
            "|    total_timesteps | 56000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -162     |\n",
            "| time/              |          |\n",
            "|    episodes        | 284      |\n",
            "|    fps             | 807      |\n",
            "|    time_elapsed    | 71       |\n",
            "|    total_timesteps | 57600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 14.1     |\n",
            "|    critic_loss     | 6.75     |\n",
            "|    ent_coef        | 0.138    |\n",
            "|    ent_coef_loss   | -1.5     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 7187     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -162     |\n",
            "| time/              |          |\n",
            "|    episodes        | 288      |\n",
            "|    fps             | 807      |\n",
            "|    time_elapsed    | 71       |\n",
            "|    total_timesteps | 57600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -158     |\n",
            "| time/              |          |\n",
            "|    episodes        | 292      |\n",
            "|    fps             | 805      |\n",
            "|    time_elapsed    | 73       |\n",
            "|    total_timesteps | 59200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 7.66     |\n",
            "|    critic_loss     | 4.67     |\n",
            "|    ent_coef        | 0.131    |\n",
            "|    ent_coef_loss   | -1.68    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 7387     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -158     |\n",
            "| time/              |          |\n",
            "|    episodes        | 296      |\n",
            "|    fps             | 805      |\n",
            "|    time_elapsed    | 73       |\n",
            "|    total_timesteps | 59200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -154     |\n",
            "| time/              |          |\n",
            "|    episodes        | 300      |\n",
            "|    fps             | 804      |\n",
            "|    time_elapsed    | 75       |\n",
            "|    total_timesteps | 60800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.6     |\n",
            "|    critic_loss     | 4.95     |\n",
            "|    ent_coef        | 0.124    |\n",
            "|    ent_coef_loss   | -1.77    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 7587     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -154     |\n",
            "| time/              |          |\n",
            "|    episodes        | 304      |\n",
            "|    fps             | 804      |\n",
            "|    time_elapsed    | 75       |\n",
            "|    total_timesteps | 60800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -156     |\n",
            "| time/              |          |\n",
            "|    episodes        | 308      |\n",
            "|    fps             | 804      |\n",
            "|    time_elapsed    | 77       |\n",
            "|    total_timesteps | 62400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.4     |\n",
            "|    critic_loss     | 5.29     |\n",
            "|    ent_coef        | 0.118    |\n",
            "|    ent_coef_loss   | -1.27    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 7787     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -156     |\n",
            "| time/              |          |\n",
            "|    episodes        | 312      |\n",
            "|    fps             | 804      |\n",
            "|    time_elapsed    | 77       |\n",
            "|    total_timesteps | 62400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -153     |\n",
            "| time/              |          |\n",
            "|    episodes        | 316      |\n",
            "|    fps             | 801      |\n",
            "|    time_elapsed    | 79       |\n",
            "|    total_timesteps | 64000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 10.1     |\n",
            "|    critic_loss     | 7.4      |\n",
            "|    ent_coef        | 0.113    |\n",
            "|    ent_coef_loss   | -1.86    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 7987     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -153     |\n",
            "| time/              |          |\n",
            "|    episodes        | 320      |\n",
            "|    fps             | 801      |\n",
            "|    time_elapsed    | 79       |\n",
            "|    total_timesteps | 64000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -157     |\n",
            "| time/              |          |\n",
            "|    episodes        | 324      |\n",
            "|    fps             | 798      |\n",
            "|    time_elapsed    | 82       |\n",
            "|    total_timesteps | 65600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 14.3     |\n",
            "|    critic_loss     | 4.98     |\n",
            "|    ent_coef        | 0.107    |\n",
            "|    ent_coef_loss   | -1.5     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 8187     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -157     |\n",
            "| time/              |          |\n",
            "|    episodes        | 328      |\n",
            "|    fps             | 798      |\n",
            "|    time_elapsed    | 82       |\n",
            "|    total_timesteps | 65600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -155     |\n",
            "| time/              |          |\n",
            "|    episodes        | 332      |\n",
            "|    fps             | 799      |\n",
            "|    time_elapsed    | 84       |\n",
            "|    total_timesteps | 67200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.9      |\n",
            "|    critic_loss     | 3.41     |\n",
            "|    ent_coef        | 0.102    |\n",
            "|    ent_coef_loss   | -1.65    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 8387     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -155     |\n",
            "| time/              |          |\n",
            "|    episodes        | 336      |\n",
            "|    fps             | 799      |\n",
            "|    time_elapsed    | 84       |\n",
            "|    total_timesteps | 67200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -154     |\n",
            "| time/              |          |\n",
            "|    episodes        | 340      |\n",
            "|    fps             | 799      |\n",
            "|    time_elapsed    | 86       |\n",
            "|    total_timesteps | 68800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 8.97     |\n",
            "|    critic_loss     | 3.65     |\n",
            "|    ent_coef        | 0.0974   |\n",
            "|    ent_coef_loss   | -1.67    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 8587     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -154     |\n",
            "| time/              |          |\n",
            "|    episodes        | 344      |\n",
            "|    fps             | 799      |\n",
            "|    time_elapsed    | 86       |\n",
            "|    total_timesteps | 68800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -156     |\n",
            "| time/              |          |\n",
            "|    episodes        | 348      |\n",
            "|    fps             | 800      |\n",
            "|    time_elapsed    | 87       |\n",
            "|    total_timesteps | 70400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.7     |\n",
            "|    critic_loss     | 6.69     |\n",
            "|    ent_coef        | 0.0926   |\n",
            "|    ent_coef_loss   | -1.38    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 8787     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -156     |\n",
            "| time/              |          |\n",
            "|    episodes        | 352      |\n",
            "|    fps             | 800      |\n",
            "|    time_elapsed    | 87       |\n",
            "|    total_timesteps | 70400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -155     |\n",
            "| time/              |          |\n",
            "|    episodes        | 356      |\n",
            "|    fps             | 800      |\n",
            "|    time_elapsed    | 89       |\n",
            "|    total_timesteps | 72000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 9.32     |\n",
            "|    critic_loss     | 3.48     |\n",
            "|    ent_coef        | 0.0881   |\n",
            "|    ent_coef_loss   | -1.56    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 8987     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -155     |\n",
            "| time/              |          |\n",
            "|    episodes        | 360      |\n",
            "|    fps             | 800      |\n",
            "|    time_elapsed    | 89       |\n",
            "|    total_timesteps | 72000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -159     |\n",
            "| time/              |          |\n",
            "|    episodes        | 364      |\n",
            "|    fps             | 796      |\n",
            "|    time_elapsed    | 92       |\n",
            "|    total_timesteps | 73600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 14.1     |\n",
            "|    critic_loss     | 7.97     |\n",
            "|    ent_coef        | 0.0835   |\n",
            "|    ent_coef_loss   | -1.33    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9187     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -159     |\n",
            "| time/              |          |\n",
            "|    episodes        | 368      |\n",
            "|    fps             | 796      |\n",
            "|    time_elapsed    | 92       |\n",
            "|    total_timesteps | 73600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -163     |\n",
            "| time/              |          |\n",
            "|    episodes        | 372      |\n",
            "|    fps             | 795      |\n",
            "|    time_elapsed    | 94       |\n",
            "|    total_timesteps | 75200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 9.34     |\n",
            "|    critic_loss     | 5.43     |\n",
            "|    ent_coef        | 0.0792   |\n",
            "|    ent_coef_loss   | -1.62    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9387     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -163     |\n",
            "| time/              |          |\n",
            "|    episodes        | 376      |\n",
            "|    fps             | 795      |\n",
            "|    time_elapsed    | 94       |\n",
            "|    total_timesteps | 75200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -164     |\n",
            "| time/              |          |\n",
            "|    episodes        | 380      |\n",
            "|    fps             | 796      |\n",
            "|    time_elapsed    | 96       |\n",
            "|    total_timesteps | 76800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.7     |\n",
            "|    critic_loss     | 5.1      |\n",
            "|    ent_coef        | 0.0749   |\n",
            "|    ent_coef_loss   | -1.57    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9587     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -164     |\n",
            "| time/              |          |\n",
            "|    episodes        | 384      |\n",
            "|    fps             | 796      |\n",
            "|    time_elapsed    | 96       |\n",
            "|    total_timesteps | 76800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -166     |\n",
            "| time/              |          |\n",
            "|    episodes        | 388      |\n",
            "|    fps             | 796      |\n",
            "|    time_elapsed    | 98       |\n",
            "|    total_timesteps | 78400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 8.49     |\n",
            "|    critic_loss     | 7.85     |\n",
            "|    ent_coef        | 0.071    |\n",
            "|    ent_coef_loss   | -1.44    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9787     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -166     |\n",
            "| time/              |          |\n",
            "|    episodes        | 392      |\n",
            "|    fps             | 796      |\n",
            "|    time_elapsed    | 98       |\n",
            "|    total_timesteps | 78400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -170     |\n",
            "| time/              |          |\n",
            "|    episodes        | 396      |\n",
            "|    fps             | 795      |\n",
            "|    time_elapsed    | 100      |\n",
            "|    total_timesteps | 80000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.53     |\n",
            "|    critic_loss     | 5.5      |\n",
            "|    ent_coef        | 0.0673   |\n",
            "|    ent_coef_loss   | -1.46    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9987     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -170     |\n",
            "| time/              |          |\n",
            "|    episodes        | 400      |\n",
            "|    fps             | 795      |\n",
            "|    time_elapsed    | 100      |\n",
            "|    total_timesteps | 80000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -171     |\n",
            "| time/              |          |\n",
            "|    episodes        | 404      |\n",
            "|    fps             | 795      |\n",
            "|    time_elapsed    | 102      |\n",
            "|    total_timesteps | 81600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 8.65     |\n",
            "|    critic_loss     | 6.11     |\n",
            "|    ent_coef        | 0.0637   |\n",
            "|    ent_coef_loss   | -1.93    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 10187    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -171     |\n",
            "| time/              |          |\n",
            "|    episodes        | 408      |\n",
            "|    fps             | 795      |\n",
            "|    time_elapsed    | 102      |\n",
            "|    total_timesteps | 81600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -167     |\n",
            "| time/              |          |\n",
            "|    episodes        | 412      |\n",
            "|    fps             | 791      |\n",
            "|    time_elapsed    | 105      |\n",
            "|    total_timesteps | 83200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 7.43     |\n",
            "|    critic_loss     | 5.8      |\n",
            "|    ent_coef        | 0.0602   |\n",
            "|    ent_coef_loss   | -1.75    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 10387    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -167     |\n",
            "| time/              |          |\n",
            "|    episodes        | 416      |\n",
            "|    fps             | 791      |\n",
            "|    time_elapsed    | 105      |\n",
            "|    total_timesteps | 83200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -171     |\n",
            "| time/              |          |\n",
            "|    episodes        | 420      |\n",
            "|    fps             | 791      |\n",
            "|    time_elapsed    | 107      |\n",
            "|    total_timesteps | 84800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 9.98     |\n",
            "|    critic_loss     | 7.09     |\n",
            "|    ent_coef        | 0.057    |\n",
            "|    ent_coef_loss   | -1.72    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 10587    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -171     |\n",
            "| time/              |          |\n",
            "|    episodes        | 424      |\n",
            "|    fps             | 791      |\n",
            "|    time_elapsed    | 107      |\n",
            "|    total_timesteps | 84800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -168     |\n",
            "| time/              |          |\n",
            "|    episodes        | 428      |\n",
            "|    fps             | 792      |\n",
            "|    time_elapsed    | 109      |\n",
            "|    total_timesteps | 86400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 8.5      |\n",
            "|    critic_loss     | 4.44     |\n",
            "|    ent_coef        | 0.0539   |\n",
            "|    ent_coef_loss   | -1.83    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 10787    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -168     |\n",
            "| time/              |          |\n",
            "|    episodes        | 432      |\n",
            "|    fps             | 792      |\n",
            "|    time_elapsed    | 109      |\n",
            "|    total_timesteps | 86400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -171     |\n",
            "| time/              |          |\n",
            "|    episodes        | 436      |\n",
            "|    fps             | 792      |\n",
            "|    time_elapsed    | 110      |\n",
            "|    total_timesteps | 88000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 14.6     |\n",
            "|    critic_loss     | 5.02     |\n",
            "|    ent_coef        | 0.051    |\n",
            "|    ent_coef_loss   | -1.79    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 10987    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -171     |\n",
            "| time/              |          |\n",
            "|    episodes        | 440      |\n",
            "|    fps             | 792      |\n",
            "|    time_elapsed    | 110      |\n",
            "|    total_timesteps | 88000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -171     |\n",
            "| time/              |          |\n",
            "|    episodes        | 444      |\n",
            "|    fps             | 792      |\n",
            "|    time_elapsed    | 113      |\n",
            "|    total_timesteps | 89600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12       |\n",
            "|    critic_loss     | 4.17     |\n",
            "|    ent_coef        | 0.0486   |\n",
            "|    ent_coef_loss   | -1.87    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 11187    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -171     |\n",
            "| time/              |          |\n",
            "|    episodes        | 448      |\n",
            "|    fps             | 792      |\n",
            "|    time_elapsed    | 113      |\n",
            "|    total_timesteps | 89600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -172     |\n",
            "| time/              |          |\n",
            "|    episodes        | 452      |\n",
            "|    fps             | 791      |\n",
            "|    time_elapsed    | 115      |\n",
            "|    total_timesteps | 91200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 7.1      |\n",
            "|    critic_loss     | 3.79     |\n",
            "|    ent_coef        | 0.0463   |\n",
            "|    ent_coef_loss   | -2.36    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 11387    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -172     |\n",
            "| time/              |          |\n",
            "|    episodes        | 456      |\n",
            "|    fps             | 791      |\n",
            "|    time_elapsed    | 115      |\n",
            "|    total_timesteps | 91200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -171     |\n",
            "| time/              |          |\n",
            "|    episodes        | 460      |\n",
            "|    fps             | 788      |\n",
            "|    time_elapsed    | 117      |\n",
            "|    total_timesteps | 92800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 14.5     |\n",
            "|    critic_loss     | 5.64     |\n",
            "|    ent_coef        | 0.0439   |\n",
            "|    ent_coef_loss   | -1.06    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 11587    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -171     |\n",
            "| time/              |          |\n",
            "|    episodes        | 464      |\n",
            "|    fps             | 788      |\n",
            "|    time_elapsed    | 117      |\n",
            "|    total_timesteps | 92800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -170     |\n",
            "| time/              |          |\n",
            "|    episodes        | 468      |\n",
            "|    fps             | 788      |\n",
            "|    time_elapsed    | 119      |\n",
            "|    total_timesteps | 94400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 10       |\n",
            "|    critic_loss     | 3.71     |\n",
            "|    ent_coef        | 0.0418   |\n",
            "|    ent_coef_loss   | -1.72    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 11787    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -170     |\n",
            "| time/              |          |\n",
            "|    episodes        | 472      |\n",
            "|    fps             | 788      |\n",
            "|    time_elapsed    | 119      |\n",
            "|    total_timesteps | 94400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -164     |\n",
            "| time/              |          |\n",
            "|    episodes        | 476      |\n",
            "|    fps             | 788      |\n",
            "|    time_elapsed    | 121      |\n",
            "|    total_timesteps | 96000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 14.8     |\n",
            "|    critic_loss     | 5.19     |\n",
            "|    ent_coef        | 0.0398   |\n",
            "|    ent_coef_loss   | -1.16    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 11987    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -164     |\n",
            "| time/              |          |\n",
            "|    episodes        | 480      |\n",
            "|    fps             | 788      |\n",
            "|    time_elapsed    | 121      |\n",
            "|    total_timesteps | 96000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -166     |\n",
            "| time/              |          |\n",
            "|    episodes        | 484      |\n",
            "|    fps             | 789      |\n",
            "|    time_elapsed    | 123      |\n",
            "|    total_timesteps | 97600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 8.77     |\n",
            "|    critic_loss     | 3.36     |\n",
            "|    ent_coef        | 0.0379   |\n",
            "|    ent_coef_loss   | -1.22    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 12187    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -166     |\n",
            "| time/              |          |\n",
            "|    episodes        | 488      |\n",
            "|    fps             | 789      |\n",
            "|    time_elapsed    | 123      |\n",
            "|    total_timesteps | 97600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -165     |\n",
            "| time/              |          |\n",
            "|    episodes        | 492      |\n",
            "|    fps             | 789      |\n",
            "|    time_elapsed    | 125      |\n",
            "|    total_timesteps | 99200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 8.34     |\n",
            "|    critic_loss     | 5.12     |\n",
            "|    ent_coef        | 0.0363   |\n",
            "|    ent_coef_loss   | -1.19    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 12387    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -165     |\n",
            "| time/              |          |\n",
            "|    episodes        | 496      |\n",
            "|    fps             | 789      |\n",
            "|    time_elapsed    | 125      |\n",
            "|    total_timesteps | 99200    |\n",
            "---------------------------------\n",
            "step: 100000 - x:1.00, y:-0.01 | theta:-0.01 theta_dot:-0.04\n",
            "step: 100000 - u_e:-0.00, u_p:0.16 | w:0.9232945506292405 u:0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ENV_ID = \"Pendulum-v1\"\n",
        "\n",
        "# baseline policy\n",
        "from pendulum_residual_rl.controllers import EnergyPDController\n",
        "baseline_ctrl = EnergyPDController(log_interval_in=100000)\n",
        "\n",
        "def baseline_policy(obs):\n",
        "    return baseline_ctrl(obs)\n",
        "\n",
        "# # residual policy needs its wrapper env\n",
        "# import gymnasium as gym\n",
        "# from pendulum_residual_rl.residual_env import ResidualWrapper\n",
        "\n",
        "def eval_residual(model, n_episodes=50, seed=0, steps=200):\n",
        "    env = ResidualWrapper(gym.make(ENV_ID), baseline_fn=baseline_ctrl, alpha=0.3)\n",
        "    returns = []\n",
        "    for i in range(n_episodes):\n",
        "        obs, _ = env.reset(seed=seed+i)\n",
        "        total = 0.0\n",
        "        for _ in range(steps):\n",
        "            a_res, _ = model.predict(obs, deterministic=True)\n",
        "            obs, r, term, trunc, _ = env.step(a_res)\n",
        "            total += r\n",
        "            if term or trunc:\n",
        "                break\n",
        "        returns.append(total)\n",
        "    env.close()\n",
        "    return float(np.mean(returns)), float(np.std(returns))\n",
        "\n",
        "mean_base, std_base = eval_policy(ENV_ID, baseline_policy, n_episodes=50, seed=0)\n",
        "mean_sac, std_sac = eval_policy(ENV_ID, lambda obs: model_sac_load.predict(obs, deterministic=True)[0], n_episodes=50, seed=0)\n",
        "mean_res, std_res = eval_residual(model_res, n_episodes=50, seed=0)\n",
        "\n",
        "print(\"Baseline:\", mean_base, \"+/-\", std_base)\n",
        "print(\"Pure SAC:\", mean_sac, \"+/-\", std_sac)\n",
        "print(\"Residual SAC:\", mean_res, \"+/-\", std_res)\n"
      ],
      "metadata": {
        "id": "1s8cUaGY96Wk",
        "outputId": "630b0ab0-0a58-4117-9c93-614238188d2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline: -162.2092957654325 +/- 74.28399628048706\n",
            "Pure SAC: -134.25982974604057 +/- 79.29318225426385\n",
            "Residual SAC: -140.88147682075984 +/- 79.27135137017504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def res_policy(obs):\n",
        "    action, _ = model_res.predict(obs, deterministic=True)\n",
        "    return action\n",
        "\n",
        "mean_res, std_res = eval_policy(ENV_ID, res_policy, n_episodes=50, seed=0)\n",
        "print(f\"Residual mean return:{mean_res:.5}\")\n",
        "print(f\"Residual std:{std_res:.5}\")"
      ],
      "metadata": {
        "id": "Q9DTr7HI9hPc",
        "outputId": "388dabb1-9973-4fc4-88a2-ea8ab65eb15d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Residual mean return:-1120.0\n",
            "Residual std:515.89\n"
          ]
        }
      ]
    }
  ]
}